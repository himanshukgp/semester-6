{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:08:15.022729Z",
     "start_time": "2019-03-23T05:08:10.659830Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd\n",
    "from mxnet.gluon import nn, rnn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:08:15.036712Z",
     "start_time": "2019-03-23T05:08:15.027171Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:51:33.155505Z",
     "start_time": "2019-03-23T05:51:33.144973Z"
    }
   },
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(path + 'train.txt')\n",
    "        random.shuffle(self.train)\n",
    "        temp = int(0.20 * self.train.shape[0])\n",
    "        self.valid = self.train[:temp]\n",
    "        self.train = self.train[temp:]\n",
    "        self.test = self.tokenize(path + 'test.txt')\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        \"\"\"Tokenizes a text file.\"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r') as f:\n",
    "            ids = np.zeros((tokens,), dtype='int32')\n",
    "            token = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    ids[token] = self.dictionary.word2idx[word]\n",
    "                    token += 1\n",
    "\n",
    "        return mx.nd.array(ids, dtype='int32')\n",
    "    \n",
    "    def to_word(self, list):\n",
    "        a = [\"dn\"]\n",
    "        print(self.dictionary.idx2word[20])\n",
    "        for word in list:\n",
    "            #print(word[0])\n",
    "            a.append(self.dictionary.idx2word[word[0]])\n",
    "        return a;\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:47:05.130984Z",
     "start_time": "2019-03-23T05:47:05.098034Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModel(gluon.Block):\n",
    "    \"\"\"A model with an encoder, recurrent layer, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, mode, vocab_size, num_embed, num_hidden,\n",
    "                 num_layers, dropout=0.5, tie_weights=False, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.drop = nn.Dropout(dropout)\n",
    "            self.encoder = nn.Embedding(vocab_size, num_embed,\n",
    "                                        weight_initializer = mx.init.Uniform(0.1))\n",
    "            if mode == 'rnn_relu':\n",
    "                self.rnn = rnn.RNN(num_hidden, num_layers, activation='relu', dropout=dropout,\n",
    "                                   input_size=num_embed)\n",
    "            elif mode == 'rnn_tanh':\n",
    "                self.rnn = rnn.RNN(num_hidden, num_layers, dropout=dropout,\n",
    "                                   input_size=num_embed)\n",
    "            elif mode == 'lstm':\n",
    "                self.rnn = rnn.LSTM(num_hidden, num_layers, dropout=dropout,\n",
    "                                    input_size=num_embed)\n",
    "            elif mode == 'gru':\n",
    "                self.rnn = rnn.GRU(num_hidden, num_layers, dropout=dropout,\n",
    "                                   input_size=num_embed)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid mode %s. Options are rnn_relu, \"\n",
    "                                 \"rnn_tanh, lstm, and gru\"%mode)\n",
    "            if tie_weights:\n",
    "                self.decoder = nn.Dense(vocab_size, in_units = num_hidden,\n",
    "                                        params = self.encoder.params)\n",
    "            else:\n",
    "                self.decoder = nn.Dense(vocab_size, in_units = num_hidden)\n",
    "            self.num_hidden = num_hidden\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        emb = self.drop(self.encoder(inputs))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output.reshape((-1, self.num_hidden)))\n",
    "        return decoded, hidden\n",
    "\n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return self.rnn.begin_state(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:47:05.875817Z",
     "start_time": "2019-03-23T05:47:05.858754Z"
    }
   },
   "outputs": [],
   "source": [
    "args_data = ''\n",
    "args_model = 'rnn_relu'\n",
    "args_emsize = 100\n",
    "args_nhid = 100\n",
    "args_nlayers = 2\n",
    "args_lr = 1.0\n",
    "args_clip = 0.2\n",
    "args_epochs = 10\n",
    "args_batch_size = 32\n",
    "args_bptt = 5\n",
    "args_dropout = 0.2\n",
    "args_tied = True\n",
    "args_cuda = 'store_true'\n",
    "args_log_interval = 500\n",
    "args_save = 'model.param'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:51:42.726804Z",
     "start_time": "2019-03-23T05:51:37.710246Z"
    }
   },
   "outputs": [],
   "source": [
    "context = mx.cpu() # this notebook takes too long on cpu\n",
    "corpus = Corpus(args_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:47:12.278291Z",
     "start_time": "2019-03-23T05:47:07.280774Z"
    }
   },
   "outputs": [],
   "source": [
    "def batchify(data, batch_size):\n",
    "    \"\"\"Reshape data into (num_example, batch_size)\"\"\"\n",
    "    nbatch = data.shape[0] // batch_size\n",
    "    data = data[:nbatch * batch_size]\n",
    "    data = data.reshape((batch_size, nbatch)).T\n",
    "    return data\n",
    "\n",
    "train_data = batchify(corpus.train, args_batch_size).as_in_context(context)\n",
    "val_data = batchify(corpus.valid, args_batch_size).as_in_context(context)\n",
    "test_data = batchify(corpus.test, args_batch_size).as_in_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T07:26:50.246450Z",
     "start_time": "2019-03-23T07:26:29.202038Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singh/anaconda3/envs/data/lib/python3.6/site-packages/mxnet/contrib/text/embedding.py:279: UserWarning: At line 1 of the pre-trained text embedding file: token 111051 with 1-dimensional vector [300.0] is likely a header and is skipped.\n",
      "  'skipped.' % (line_num, token, elems))\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "from mxnet.contrib import text\n",
    "import collections\n",
    "\n",
    "args_lr = 0.001\n",
    "args_batch_size = 32\n",
    "\n",
    "train_data = pd.read_fwf('train.txt',header=None)\n",
    "test_data = pd.read_fwf('test.txt')\n",
    "\n",
    "train = train_data.values\n",
    "\n",
    "train_data = train_data[0]\n",
    "\n",
    "def clean_document(doco):\n",
    "    punctuation = string.punctuation + '\\n\\n';\n",
    "    punc_replace = ''.join([' ' for s in punctuation]);\n",
    "    doco_clean = doco.replace('-', ' ');\n",
    "    doco_alphas = re.sub(r'\\W +', '', doco_clean)\n",
    "    trans_table = str.maketrans(punctuation, punc_replace);\n",
    "    doco_clean = ' '.join([word.translate(trans_table) for word in doco_alphas.split(' ')]);\n",
    "    doco_clean = doco_clean.split(' ');\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    doco_clean = [regex.sub(\"\", word.lower()) for word in doco_clean if len(word) > 0];\n",
    "    \n",
    "    return doco_clean;\n",
    "\n",
    "data_to_clean = [line[0] for line in train_data];\n",
    "\n",
    "data_clean = [clean_document(doc) for doc in train_data]\n",
    "sentences = [' '.join(r) for r in data_clean]\n",
    "\n",
    "for line in sentences:\n",
    "    line = re.sub(' +', ' ', line)\n",
    "\n",
    "counter = text.utils.count_tokens_from_str('\\n'.join(sentences))\n",
    "my_vocab = text.vocab.Vocabulary(counter, unknown_token='&lt;unk&gt;', \n",
    "                                 reserved_tokens=['&lt;pad&gt;'])\n",
    "\n",
    "my_embedding = text.embedding.create('fasttext', pretrained_file_name='wiki.simple.vec', \n",
    "                                     vocabulary=my_vocab)\n",
    "\n",
    "# my_embedding = text.embedding.create('glove', pretrained_file_name='glove.6B.50d.txt', \n",
    "#                                      vocabulary=my_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:56:11.509523Z",
     "start_time": "2019-03-23T05:56:11.502389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[214]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:08:20.664553Z",
     "start_time": "2019-03-23T05:08:20.615611Z"
    }
   },
   "outputs": [],
   "source": [
    "ntokens = len(corpus.dictionary)\n",
    "\n",
    "model = RNNModel(args_model, ntokens, args_emsize, args_nhid,\n",
    "                       args_nlayers, args_dropout, args_tied)\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx=context)\n",
    "trainer = gluon.Trainer(model.collect_params(), 'sgd',\n",
    "                        {'learning_rate': args_lr, 'momentum': 0, 'wd': 0})\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:08:20.769767Z",
     "start_time": "2019-03-23T05:08:20.668717Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batch(source, i):\n",
    "    seq_len = min(args_bptt, source.shape[0] - 1 - i)\n",
    "    data = source[i : i + seq_len]\n",
    "    target = source[i + 1 : i + 1 + seq_len]\n",
    "    return data, target.reshape((-1,))\n",
    "\n",
    "def detach(hidden):\n",
    "    if isinstance(hidden, (tuple, list)):\n",
    "        hidden = [i.detach() for i in hidden]\n",
    "    else:\n",
    "        hidden = hidden.detach()\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:08:20.904584Z",
     "start_time": "2019-03-23T05:08:20.773113Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval(data_source):\n",
    "    total_L = 0.0\n",
    "    ntotal = 0\n",
    "    hidden = model.begin_state(func = mx.nd.zeros, batch_size = args_batch_size, ctx=context)\n",
    "    for i in range(0, data_source.shape[0] - 1, args_bptt):\n",
    "        data, target = get_batch(data_source, i)\n",
    "        output, hidden = model(data, hidden)\n",
    "        L = loss(output, target)\n",
    "        total_L += mx.nd.sum(L).asscalar()\n",
    "        ntotal += L.size\n",
    "    return total_L / ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:08:21.099281Z",
     "start_time": "2019-03-23T05:08:20.908807Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    args_lr = 1.0\n",
    "    best_val = float(\"Inf\")\n",
    "    for epoch in range(args_epochs):\n",
    "        total_L = 0.0\n",
    "        start_time = time.time()\n",
    "        hidden = model.begin_state(func = mx.nd.zeros, batch_size = args_batch_size, ctx = context)\n",
    "        for ibatch, i in enumerate(range(0, train_data.shape[0] - 1, args_bptt)):\n",
    "            data, target = get_batch(train_data, i)\n",
    "            hidden = detach(hidden)\n",
    "            with autograd.record():\n",
    "                output, hidden = model(data, hidden)\n",
    "                L = loss(output, target)\n",
    "                L.backward()\n",
    "\n",
    "            grads = [i.grad(context) for i in model.collect_params().values()]\n",
    "            # Here gradient is for the whole batch.\n",
    "            # So we multiply max_norm by batch_size and bptt size to balance it.\n",
    "            gluon.utils.clip_global_norm(grads, args_clip * args_bptt * args_batch_size)\n",
    "\n",
    "            trainer.step(args_batch_size)\n",
    "            total_L += mx.nd.sum(L).asscalar()\n",
    "\n",
    "            if ibatch % args_log_interval == 0 and ibatch > 0:\n",
    "                cur_L = total_L / args_bptt / args_batch_size / args_log_interval\n",
    "                print('[Epoch %d Batch %d] loss %.2f, perplexity %.2f' % (\n",
    "                    epoch + 1, ibatch, cur_L, math.exp(cur_L)))\n",
    "                total_L = 0.0\n",
    "\n",
    "        val_L = eval(val_data)\n",
    "\n",
    "        print('[Epoch %d] time cost %.2fs, validation loss %.2f, validation perplexity %.2f' % (\n",
    "            epoch + 1, time.time() - start_time, val_L, math.exp(val_L)))\n",
    "\n",
    "        if val_L < best_val:\n",
    "            best_val = val_L\n",
    "            test_L = eval(test_data)\n",
    "            model.save_parameters(args_save)\n",
    "            print('test loss %.2f, test perplexity %.2f' % (test_L, math.exp(test_L)))\n",
    "        else:\n",
    "            args_lr = args_lr * 0.25\n",
    "            trainer._init_optimizer('sgd',\n",
    "                                    {'learning_rate': args_lr,\n",
    "                                     'momentum': 0,\n",
    "                                     'wd': 0})\n",
    "            model.load_parameters(args_save, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:10:32.152654Z",
     "start_time": "2019-03-23T05:08:21.103673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] time cost 12.01s, validation loss 7.19, validation perplexity 1319.99\n",
      "test loss 7.16, test perplexity 1283.61\n",
      "[Epoch 2] time cost 12.55s, validation loss 6.94, validation perplexity 1030.70\n",
      "test loss 6.94, test perplexity 1032.37\n",
      "[Epoch 3] time cost 12.75s, validation loss 6.96, validation perplexity 1057.54\n",
      "[Epoch 4] time cost 11.48s, validation loss 6.86, validation perplexity 950.20\n",
      "test loss 6.90, test perplexity 991.87\n",
      "[Epoch 5] time cost 12.18s, validation loss 6.85, validation perplexity 941.05\n",
      "test loss 6.91, test perplexity 1005.63\n",
      "[Epoch 6] time cost 11.57s, validation loss 6.84, validation perplexity 934.57\n",
      "test loss 6.93, test perplexity 1022.18\n",
      "[Epoch 7] time cost 11.78s, validation loss 6.84, validation perplexity 931.16\n",
      "test loss 6.94, test perplexity 1036.45\n",
      "[Epoch 8] time cost 11.85s, validation loss 6.84, validation perplexity 930.86\n",
      "test loss 6.96, test perplexity 1054.59\n",
      "[Epoch 9] time cost 11.06s, validation loss 6.84, validation perplexity 934.20\n",
      "[Epoch 10] time cost 12.32s, validation loss 6.82, validation perplexity 916.08\n",
      "test loss 6.96, test perplexity 1054.42\n",
      "Best test loss 6.96, test perplexity 1054.42\n"
     ]
    }
   ],
   "source": [
    "train()\n",
    "model.load_parameters(args_save, context)\n",
    "test_L = eval(test_data)\n",
    "print('Best test loss %.2f, test perplexity %.2f'%(test_L, math.exp(test_L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:10:32.167232Z",
     "start_time": "2019-03-23T05:10:32.155757Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval1(data_source):\n",
    "    total_L = 0.0\n",
    "    ntotal = 0\n",
    "    hidden = model.begin_state(func = mx.nd.zeros, batch_size = args_batch_size, ctx=context)\n",
    "    for i in range(0, 1, args_bptt):\n",
    "        data, target = get_batch(data_source, i)\n",
    "        print(data,target)\n",
    "        output, hidden = model(data, hidden)\n",
    "        L = loss(output, target)\n",
    "        total_L += mx.nd.sum(L).asscalar()\n",
    "        ntotal += L.size\n",
    "    return [output, target, total_L / ntotal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:10:48.124290Z",
     "start_time": "2019-03-23T05:10:48.060647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 744   94 3095   12 7097  197  443   90   12 7246 7263 1951   38   49\n",
      "  4666  736 7458  633    6  219  371 3455   52   56 1053  515  529    2\n",
      "  2100 4482   12   95]\n",
      " [   6   12 7043  910   12 1485   26   48  346 1814   34  119   12  818\n",
      "    26 4797  378  139 3553  773  139 5678 7598  207 5934  387   52 4461\n",
      "  5878 7773 3512   12]\n",
      " [6980  214   12  664 1913 7141  415   40 2461 1815 5839 1053    0 7361\n",
      "   450  314    6    6 1766    8   77   19 3235   26   12   12   91    8\n",
      "    52 7774 7800  127]\n",
      " [3426  498  214  119  103   12  120 7199   26  186   12  378 2605   34\n",
      "   103   12  478 7482 7365 3130 1977 5028   12   52   77  160 1208    6\n",
      "  1656   52   26  520]\n",
      " [  67  249  249 1209  344  214  214   34 1458 7246   46   52   26  124\n",
      "  2481  888 7180 7483   12 7531  219 1751 7599 1766 1053  780 7696 2972\n",
      "  6883 7775    6  788]]\n",
      "<NDArray 5x32 @cpu(0)> \n",
      "[   6   12 7043  910   12 1485   26   48  346 1814   34  119   12  818\n",
      "   26 4797  378  139 3553  773  139 5678 7598  207 5934  387   52 4461\n",
      " 5878 7773 3512   12 6980  214   12  664 1913 7141  415   40 2461 1815\n",
      " 5839 1053    0 7361  450  314    6    6 1766    8   77   19 3235   26\n",
      "   12   12   91    8   52 7774 7800  127 3426  498  214  119  103   12\n",
      "  120 7199   26  186   12  378 2605   34  103   12  478 7482 7365 3130\n",
      " 1977 5028   12   52   77  160 1208    6 1656   52   26  520   67  249\n",
      "  249 1209  344  214  214   34 1458 7246   46   52   26  124 2481  888\n",
      " 7180 7483   12 7531  219 1751 7599 1766 1053  780 7696 2972 6883 7775\n",
      "    6  788  126  216 1052   49 7100 1805 2208  119   48   12 2650  379\n",
      " 1049  827  687  119   26 1982   90 1986   52   12   64  443  387    6\n",
      "   12  384  443 1505  529  214]\n",
      "<NDArray 160 @cpu(0)>\n",
      "6.884042358398437\n"
     ]
    }
   ],
   "source": [
    "out,tar,p = eval1(test_data)\n",
    "#corpus.to_word(out)\n",
    "#print(out,tar)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:11:35.083835Z",
     "start_time": "2019-03-23T05:11:35.068748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data)",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
